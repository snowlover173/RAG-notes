{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d99abe44-e20d-46af-b70b-79bf4e72bc02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    " import boto3, json, sagemaker\n",
    "from typing import Dict\n",
    "from langchain import LLMChain\n",
    "from langchain.docstore.document import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.llms import SagemakerEndpoint\n",
    "from langchain.llms.sagemaker_endpoint import LLMContentHandler\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1091b-2c44-48a9-af36-ead41e1c6b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AmazonTextractPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3739e7-3e5d-40a1-a608-4ced69d4bf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pypdf Pillow\n",
    "# !pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73a4dfb3-8f70-40c3-bee8-008106cef710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n",
      "-------------!"
     ]
    }
   ],
   "source": [
    " role = sagemaker.get_execution_role()\n",
    "\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'mistralai/Mistral-7B-Instruct-v0.1',\n",
    "\t'SM_NUM_GPUS': '1'\n",
    "}\n",
    "\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"1.1.0\"),\n",
    "\tenv=hub,\n",
    "\trole=role \n",
    ")\n",
    "\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1,\n",
    "\tinstance_type=\"ml.g5.2xlarge\",\n",
    "\tcontainer_startup_health_check_timeout=300,\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90aee4ee-d544-473a-b177-f10334d77a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'huggingface-pytorch-tgi-inference-2023-12-04-01-42-20-979'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "188a2cc2-d6e6-47ff-9c95-c8de62153bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs = {\"max_new_tokens\": 512, \"top_p\": 0.8, \"temperature\": 0.8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f16dbb81-483d-4148-8d12-65c41097e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContentHandler(LLMContentHandler):\n",
    "    content_type = \"application/json\"\n",
    "    accepts = \"application/json\"\n",
    "\n",
    "    def transform_input(self, prompt: str, model_kwargs: Dict) -> bytes:\n",
    "        input_str = json.dumps(\n",
    "            # Mistral prompt, see https://huggingface.co/mistralai/Mistral-7B-Instruct-v0.1\n",
    "            {\"inputs\": f\"<s>[INST] {prompt} [/INST]\", \"parameters\": {**model_kwargs}}\n",
    "        )\n",
    "        return input_str.encode(\"utf-8\")\n",
    "\n",
    "    def transform_output(self, output: bytes) -> str:\n",
    "        response_json = json.loads(output.read().decode(\"utf-8\"))\n",
    "        splits = response_json[0][\"generated_text\"].split(\"[/INST] \")\n",
    "        return splits[1]\n",
    "\n",
    "content_handler = ContentHandler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d37b207-9143-4a34-b08b-94047b4f1e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_client = boto3.client(\"sagemaker-runtime\") # needed for AWS credentials\n",
    "\n",
    "llm = SagemakerEndpoint(\n",
    "    endpoint_name=endpoint_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    content_handler=content_handler,\n",
    "    client=sm_client,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78403e40-4b47-4cb9-8ca9-a8afa9053db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32feda36-9f63-4966-a902-b0c5df514c9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6d65537d-5343-48b7-b266-82bde4c81263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "bucket = sagemaker.Session().default_bucket()\n",
    "prefix = \"grade-10-science\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf8318-5a6e-47f9-a115-0be36cd19b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh -s $bucket $prefix\n",
    "aws s3 cp --recursive files s3://$1/$2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833fa8dd-0442-4aab-9612-e5c71e9b9315",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "objs = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)\n",
    "objs = objs['Contents']\n",
    "uris = [f's3://{bucket}/{obj[\"Key\"]}' for obj in objs]\n",
    "uris "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175c38a-8545-4cfb-b4df-f52369444f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "textract_client = boto3.client('textract')\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=256, chunk_overlap=0)\n",
    "\n",
    "all_chunks = []\n",
    "\n",
    "for uri in uris:\n",
    "    print(uri)\n",
    "    loader = AmazonTextractPDFLoader(uri, client=textract_client)\n",
    "    print(loader)\n",
    "    document = loader.load()\n",
    "    chunks = splitter.split_documents(document)\n",
    "    all_chunks += chunks\n",
    "    print(f\"Loaded {uri}, {len(document)} pages, {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3ac150dd-4bb3-4bde-b5fe-8ddabbc8ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define embedding model\n",
    "# See https://huggingface.co/spaces/mteb/leaderboard\n",
    "\n",
    "embedding_model_id = \"BAAI/bge-small-en-v1.5\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=embedding_model_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45911680-558d-43e5-a621-84dbe9b8b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Embed chunks\n",
    "embeddings_db = FAISS.from_documents(all_chunks, embeddings)\n",
    "# Save database\n",
    "embeddings_db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f1c4795-5a8a-4bc9-8c9e-0a0ef719c46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_db = FAISS.load_local(\"faiss_index\", embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "396f2ba7-6fb7-4dec-b240-5547051414c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = embeddings_db.as_retriever(search_kwargs={\"k\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e909e342-f80b-403e-ac75-d3b2c1cea8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define prompt template\n",
    "prompt_template = \"\"\"\n",
    "As a school teacher assistant answer the following question, considering the following content:.\n",
    "\n",
    "question: {question}\n",
    "\n",
    "context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d435cc06-1a90-409a-9a15-5a236381299a",
   "metadata": {},
   "outputs": [],
   "source": [
    " chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever, \n",
    "    chain_type_kwargs = {\"prompt\": prompt})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ba839-3428-4b49-94c3-595f8fd636c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime;\n",
    " \n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "\n",
    "question = \"create teaching plan for 14 sessions on the topic of modern physics\"\n",
    "answer = chain.run({\"query\": question})\n",
    "file_name= \"teaching_plan\"+str(ct)+\".txt\"\n",
    "with open(file_name,'a') as f:\n",
    "    f.write(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2506d74c-4e05-4c0a-a5af-459f933bc4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"split the content on quantum mechanics to three sections. Create 20 exam questions for each section.\"\n",
    "answer = chain.run({\"query\": question})\n",
    "file_name= \"exam_questions\"+str(ct)+\".txt\"\n",
    "with open(file_name,'a') as f:\n",
    "    f.write(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "151ed6b6-e212-41db-bbe7-cb86f52c57af",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed7c92-16ba-4dcf-b756-b22a762b926e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6e6717-5efe-4b4d-8ba4-b08487774b66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
